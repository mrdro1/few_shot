{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "from razdel import sentenize, tokenize\n",
    "from bpe import Encoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_(text):\n",
    "    tokens = tokenize(text)\n",
    "    return [_.text for _ in tokens]\n",
    "    \n",
    "def remove_tags(text):\n",
    "    text  = re.sub(\"<.*?>\", \"\", text).replace('\\n', ' ').replace('&nbsp;', ' ').replace('&mdash;', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736098c90eb489f9361b22af19d5a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8a81ab7bda8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/ria.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-8a81ab7bda8b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/ria.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fn = 'data/ria.json'\n",
    "data = [json.loads(line) for line in tqdm(open(fn, 'r', encoding='UTF-8'))] \n",
    "texts = [_['title'] + '. ' + _['text']  for _ in tqdm(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = Parallel(n_jobs=4)(delayed(remove_tags)(_) for _ in tqdm(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/text.txt', 'w', encoding='UTF-8') as f:\n",
    "    f.write('\\n'.join(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3642dd594c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize_\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# params chosen for demonstration purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bpe_enc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sents' is not defined"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "\n",
    "encoder = Encoder(VOCAB_SIZE, word_tokenizer=tokenize_)  # params chosen for demonstration purposes\n",
    "encoder.fit(sents)\n",
    "encoder.save('bpe_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30000\n",
    "\n",
    "encoder = Encoder(VOCAB_SIZE, word_tokenizer=tokenize_) \n",
    "\n",
    "encoder = encoder.load('bpe_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[755,\n",
       " 228,\n",
       " 2,\n",
       " 139,\n",
       " 3053,\n",
       " 24000,\n",
       " 24378,\n",
       " 24232,\n",
       " 24067,\n",
       " 24001,\n",
       " 4,\n",
       " 63,\n",
       " 18,\n",
       " 5821,\n",
       " 2,\n",
       " 12,\n",
       " 24000,\n",
       " 14477,\n",
       " 24030,\n",
       " 1960,\n",
       " 24001,\n",
       " 3,\n",
       " 36,\n",
       " 2,\n",
       " 541,\n",
       " 462,\n",
       " 9,\n",
       " 16,\n",
       " 15,\n",
       " 3,\n",
       " 1163,\n",
       " 287,\n",
       " 18,\n",
       " 2501,\n",
       " 228,\n",
       " 2,\n",
       " 139,\n",
       " 1599,\n",
       " 63,\n",
       " 3053,\n",
       " 13648,\n",
       " 18,\n",
       " 5821,\n",
       " 4,\n",
       " 11290,\n",
       " 4,\n",
       " 24000,\n",
       " 30,\n",
       " 24073,\n",
       " 246,\n",
       " 24052,\n",
       " 24124,\n",
       " 2075,\n",
       " 24023,\n",
       " 24001,\n",
       " 1189,\n",
       " 19654,\n",
       " 2,\n",
       " 12,\n",
       " 658,\n",
       " 24000,\n",
       " 14477,\n",
       " 24030,\n",
       " 4094,\n",
       " 24073,\n",
       " 24001,\n",
       " 2,\n",
       " 104,\n",
       " 4,\n",
       " 321,\n",
       " 292,\n",
       " 1937,\n",
       " 1152,\n",
       " 66,\n",
       " 653,\n",
       " 7,\n",
       " 804,\n",
       " 1154,\n",
       " 635,\n",
       " 239,\n",
       " 5,\n",
       " 4261,\n",
       " 5616,\n",
       " 22819,\n",
       " 5,\n",
       " 13,\n",
       " 22819,\n",
       " 24000,\n",
       " 24586,\n",
       " 24676,\n",
       " 25077,\n",
       " 16645,\n",
       " 24001,\n",
       " 459,\n",
       " 1001,\n",
       " 24000,\n",
       " 10671,\n",
       " 24631,\n",
       " 11016,\n",
       " 6021,\n",
       " 24001,\n",
       " 14,\n",
       " 2,\n",
       " 24000,\n",
       " 17089,\n",
       " 24122,\n",
       " 24241,\n",
       " 24187,\n",
       " 24204,\n",
       " 24023,\n",
       " 24001,\n",
       " 581,\n",
       " 2599,\n",
       " 2,\n",
       " 24000,\n",
       " 23771,\n",
       " 4094,\n",
       " 24212,\n",
       " 223,\n",
       " 24105,\n",
       " 24001,\n",
       " 136,\n",
       " 2118,\n",
       " 27,\n",
       " 841,\n",
       " 998,\n",
       " 24000,\n",
       " 24133,\n",
       " 24078,\n",
       " 24084,\n",
       " 24145,\n",
       " 24001,\n",
       " 24000,\n",
       " 24035,\n",
       " 12268,\n",
       " 24090,\n",
       " 24001,\n",
       " 13,\n",
       " 24000,\n",
       " 24739,\n",
       " 24667,\n",
       " 24590,\n",
       " 24602,\n",
       " 24001,\n",
       " 24000,\n",
       " 24876,\n",
       " 19156,\n",
       " 24572,\n",
       " 24001,\n",
       " 14,\n",
       " 2,\n",
       " 24000,\n",
       " 24132,\n",
       " 24060,\n",
       " 8678,\n",
       " 24214,\n",
       " 24123,\n",
       " 24001,\n",
       " 306,\n",
       " 5,\n",
       " 1745,\n",
       " 15311,\n",
       " 22819,\n",
       " 5,\n",
       " 4,\n",
       " 1478,\n",
       " 4717,\n",
       " 2,\n",
       " 8503,\n",
       " 6,\n",
       " 7,\n",
       " 24000,\n",
       " 24052,\n",
       " 24060,\n",
       " 24157,\n",
       " 4463,\n",
       " 24001,\n",
       " 2,\n",
       " 24000,\n",
       " 8,\n",
       " 19538,\n",
       " 43,\n",
       " 24060,\n",
       " 4,\n",
       " 24001,\n",
       " 10,\n",
       " 2616,\n",
       " 98,\n",
       " 24000,\n",
       " 492,\n",
       " 24413,\n",
       " 246,\n",
       " 13973,\n",
       " 24001,\n",
       " 2,\n",
       " 11,\n",
       " 2408,\n",
       " 976,\n",
       " 18,\n",
       " 151,\n",
       " 20458,\n",
       " 3,\n",
       " 695,\n",
       " 1062,\n",
       " 1508,\n",
       " 3413,\n",
       " 322,\n",
       " 15557,\n",
       " 17404,\n",
       " 6,\n",
       " 4178,\n",
       " 8412,\n",
       " 2,\n",
       " 11,\n",
       " 2194,\n",
       " 389,\n",
       " 15585,\n",
       " 10,\n",
       " 62,\n",
       " 8793,\n",
       " 3,\n",
       " 4,\n",
       " 33,\n",
       " 321,\n",
       " 24000,\n",
       " 10248,\n",
       " 24079,\n",
       " 10854,\n",
       " 846,\n",
       " 24123,\n",
       " 24001,\n",
       " 730,\n",
       " 4692,\n",
       " 24000,\n",
       " 2372,\n",
       " 24105,\n",
       " 633,\n",
       " 24239,\n",
       " 4463,\n",
       " 24001,\n",
       " 275,\n",
       " 63,\n",
       " 2,\n",
       " 2707,\n",
       " 4,\n",
       " 4581,\n",
       " 136,\n",
       " 2424,\n",
       " 13648,\n",
       " 49,\n",
       " 170,\n",
       " 228,\n",
       " 4,\n",
       " 24000,\n",
       " 30,\n",
       " 24073,\n",
       " 246,\n",
       " 24052,\n",
       " 24124,\n",
       " 24132,\n",
       " 15269,\n",
       " 24001,\n",
       " 6147,\n",
       " 3,\n",
       " 134,\n",
       " 24000,\n",
       " 24157,\n",
       " 24512,\n",
       " 24084,\n",
       " 8876,\n",
       " 2075,\n",
       " 24023,\n",
       " 24001,\n",
       " 1390,\n",
       " 4,\n",
       " 325,\n",
       " 24000,\n",
       " 24092,\n",
       " 24060,\n",
       " 11949,\n",
       " 18901,\n",
       " 24001,\n",
       " 1813,\n",
       " 2695,\n",
       " 24000,\n",
       " 24244,\n",
       " 963,\n",
       " 24191,\n",
       " 24001,\n",
       " 24000,\n",
       " 24525,\n",
       " 3389,\n",
       " 24001,\n",
       " 24000,\n",
       " 25103,\n",
       " 13311,\n",
       " 24275,\n",
       " 24310,\n",
       " 24001,\n",
       " 13,\n",
       " 24000,\n",
       " 24690,\n",
       " 24395,\n",
       " 24001,\n",
       " 24000,\n",
       " 8466,\n",
       " 25070,\n",
       " 24918,\n",
       " 24962,\n",
       " 24001,\n",
       " 14,\n",
       " 81,\n",
       " 2,\n",
       " 11,\n",
       " 8566,\n",
       " 1705,\n",
       " 7,\n",
       " 5821,\n",
       " 4,\n",
       " 756,\n",
       " 268,\n",
       " 2,\n",
       " 24000,\n",
       " 8,\n",
       " 12096,\n",
       " 10248,\n",
       " 24214,\n",
       " 1002,\n",
       " 24001,\n",
       " 2599,\n",
       " 2,\n",
       " 52,\n",
       " 1689,\n",
       " 136,\n",
       " 2118,\n",
       " 47,\n",
       " 13046,\n",
       " 1880,\n",
       " 194,\n",
       " 244,\n",
       " 3,\n",
       " 24000,\n",
       " 25103,\n",
       " 13311,\n",
       " 24275,\n",
       " 24310,\n",
       " 24001,\n",
       " 34,\n",
       " 58,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 137,\n",
       " 3074,\n",
       " 32,\n",
       " 3011,\n",
       " 6,\n",
       " 4846,\n",
       " 2,\n",
       " 6,\n",
       " 75,\n",
       " 15169,\n",
       " 2,\n",
       " 11,\n",
       " 41,\n",
       " 151,\n",
       " 6999,\n",
       " 46,\n",
       " 1973,\n",
       " 1046,\n",
       " 2,\n",
       " 17221,\n",
       " 13648,\n",
       " 228,\n",
       " 4,\n",
       " 11290,\n",
       " 4,\n",
       " 24000,\n",
       " 30,\n",
       " 24073,\n",
       " 246,\n",
       " 24052,\n",
       " 24124,\n",
       " 2075,\n",
       " 24023,\n",
       " 24001,\n",
       " 1189,\n",
       " 19654,\n",
       " 3,\n",
       " 4,\n",
       " 245,\n",
       " 48,\n",
       " 46,\n",
       " 211,\n",
       " 1062,\n",
       " 2,\n",
       " 24,\n",
       " 4198,\n",
       " 18466,\n",
       " 3276,\n",
       " 2,\n",
       " 24000,\n",
       " 8093,\n",
       " 24028,\n",
       " 963,\n",
       " 24214,\n",
       " 1002,\n",
       " 24001,\n",
       " 28,\n",
       " 24000,\n",
       " 24084,\n",
       " 68,\n",
       " 24204,\n",
       " 246,\n",
       " 67,\n",
       " 24001,\n",
       " 2,\n",
       " 128,\n",
       " 99,\n",
       " 12461,\n",
       " 2,\n",
       " 615,\n",
       " 4,\n",
       " 24000,\n",
       " 24249,\n",
       " 24229,\n",
       " 28,\n",
       " 43,\n",
       " 24060,\n",
       " 633,\n",
       " 24063,\n",
       " 40,\n",
       " 999,\n",
       " 24001,\n",
       " 381,\n",
       " 239,\n",
       " 4,\n",
       " 325,\n",
       " 24000,\n",
       " 24153,\n",
       " 24398,\n",
       " 24533,\n",
       " 24514,\n",
       " 24263,\n",
       " 24221,\n",
       " 2688,\n",
       " 24001,\n",
       " 13,\n",
       " 24000,\n",
       " 25035,\n",
       " 25177,\n",
       " 6497,\n",
       " 24001,\n",
       " 24000,\n",
       " 6351,\n",
       " 1001,\n",
       " 24001,\n",
       " 24000,\n",
       " 24829,\n",
       " 26118,\n",
       " 25113,\n",
       " 24927,\n",
       " 24001,\n",
       " 14,\n",
       " 2,\n",
       " 6715,\n",
       " 4,\n",
       " 194,\n",
       " 1338,\n",
       " 21,\n",
       " 24000,\n",
       " 24142,\n",
       " 24083,\n",
       " 24030,\n",
       " 24646,\n",
       " 23771,\n",
       " 68,\n",
       " 24132,\n",
       " 24001,\n",
       " 28,\n",
       " 441,\n",
       " 5821,\n",
       " 24000,\n",
       " 8,\n",
       " 21923,\n",
       " 24647,\n",
       " 24358,\n",
       " 24038,\n",
       " 24124,\n",
       " 26,\n",
       " 24001,\n",
       " 3,\n",
       " 8,\n",
       " 64,\n",
       " 24000,\n",
       " 24035,\n",
       " 12268,\n",
       " 24090,\n",
       " 24001,\n",
       " 2,\n",
       " 17168,\n",
       " 4775,\n",
       " 24000,\n",
       " 24089,\n",
       " 24360,\n",
       " 24374,\n",
       " 6,\n",
       " 24001,\n",
       " 12,\n",
       " 3691,\n",
       " 2,\n",
       " 1881,\n",
       " 3246,\n",
       " 2,\n",
       " 11,\n",
       " 1002,\n",
       " 84,\n",
       " 188,\n",
       " 625,\n",
       " 3,\n",
       " 444,\n",
       " 5,\n",
       " 1745,\n",
       " 15311,\n",
       " 22819,\n",
       " 5,\n",
       " 7,\n",
       " 5821,\n",
       " 12029,\n",
       " 12,\n",
       " 148,\n",
       " 24000,\n",
       " 14477,\n",
       " 24030,\n",
       " 8876,\n",
       " 24066,\n",
       " 999,\n",
       " 24001,\n",
       " 24000,\n",
       " 9052,\n",
       " 24273,\n",
       " 68,\n",
       " 999,\n",
       " 24001,\n",
       " 6,\n",
       " 12,\n",
       " 22683,\n",
       " 228,\n",
       " 7,\n",
       " 12222,\n",
       " 3,\n",
       " 85,\n",
       " 24000,\n",
       " 10248,\n",
       " 24079,\n",
       " 10854,\n",
       " 846,\n",
       " 24111,\n",
       " 24001,\n",
       " 24000,\n",
       " 24044,\n",
       " 633,\n",
       " 24161,\n",
       " 24077,\n",
       " 24549,\n",
       " 331,\n",
       " 24159,\n",
       " 24385,\n",
       " 24001,\n",
       " 3686,\n",
       " 2,\n",
       " 11,\n",
       " 24,\n",
       " 2616,\n",
       " 2,\n",
       " 24000,\n",
       " 23771,\n",
       " 4094,\n",
       " 24212,\n",
       " 223,\n",
       " 24084,\n",
       " 67,\n",
       " 24001,\n",
       " 24000,\n",
       " 14477,\n",
       " 24030,\n",
       " 4094,\n",
       " 24073,\n",
       " 24001,\n",
       " 47,\n",
       " 1880,\n",
       " 2,\n",
       " 24000,\n",
       " 24314,\n",
       " 28,\n",
       " 24223,\n",
       " 24105,\n",
       " 24001,\n",
       " 24000,\n",
       " 24115,\n",
       " 30,\n",
       " 24235,\n",
       " 24360,\n",
       " 24001,\n",
       " 6,\n",
       " 24000,\n",
       " 68,\n",
       " 12268,\n",
       " 24022,\n",
       " 24438,\n",
       " 24001,\n",
       " 3280,\n",
       " 20,\n",
       " 51,\n",
       " 17,\n",
       " 20,\n",
       " 51,\n",
       " 17,\n",
       " 27,\n",
       " 654,\n",
       " 1937,\n",
       " 1152,\n",
       " 2,\n",
       " 47,\n",
       " 20876,\n",
       " 4508,\n",
       " 7,\n",
       " 5821,\n",
       " 65,\n",
       " 2917,\n",
       " 472,\n",
       " 1815,\n",
       " 10650,\n",
       " 2,\n",
       " 272,\n",
       " 655,\n",
       " 748,\n",
       " 96,\n",
       " 24000,\n",
       " 24245,\n",
       " 24515,\n",
       " 24089,\n",
       " 6280,\n",
       " 24001,\n",
       " 24000,\n",
       " 24154,\n",
       " 24063,\n",
       " 24060,\n",
       " 4,\n",
       " 24001,\n",
       " 319,\n",
       " 2046,\n",
       " 6430,\n",
       " 12421,\n",
       " 11881,\n",
       " 3,\n",
       " 889,\n",
       " 2529,\n",
       " 1123,\n",
       " 148,\n",
       " 24000,\n",
       " 9052,\n",
       " 331,\n",
       " 24264,\n",
       " 24029,\n",
       " 24111,\n",
       " 24001,\n",
       " 8439,\n",
       " 6253,\n",
       " 15145,\n",
       " 228,\n",
       " 22,\n",
       " 14038,\n",
       " 3519,\n",
       " 4,\n",
       " 752,\n",
       " 24000,\n",
       " 24257,\n",
       " 23771,\n",
       " 26,\n",
       " 24001,\n",
       " 2,\n",
       " 24000,\n",
       " 24318,\n",
       " 24302,\n",
       " 24204,\n",
       " 19538,\n",
       " 24001,\n",
       " 4,\n",
       " 242,\n",
       " 47,\n",
       " 20876,\n",
       " 4508,\n",
       " 3,\n",
       " 8,\n",
       " 87,\n",
       " 13319,\n",
       " 595,\n",
       " 7,\n",
       " 5821,\n",
       " 2,\n",
       " 119,\n",
       " 228,\n",
       " 901,\n",
       " 105,\n",
       " 24000,\n",
       " 24028,\n",
       " 24450,\n",
       " 24279,\n",
       " 24029,\n",
       " 24017,\n",
       " 24001,\n",
       " 10,\n",
       " 8793,\n",
       " 74,\n",
       " 18746,\n",
       " 62,\n",
       " 4,\n",
       " 171,\n",
       " 174,\n",
       " 10945,\n",
       " 2716,\n",
       " 188,\n",
       " 6,\n",
       " 14632,\n",
       " 2,\n",
       " 13449,\n",
       " 41,\n",
       " 3310,\n",
       " 93,\n",
       " 24000,\n",
       " 23771,\n",
       " 24078,\n",
       " 24022,\n",
       " 40,\n",
       " 19538,\n",
       " 24001,\n",
       " 295,\n",
       " 194,\n",
       " 244,\n",
       " 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('data/text.txt', 'r', encoding='UTF-8')\n",
    "list(encoder.transform([next(file).strip()]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "\n",
    "def gen_train():\n",
    "    file = open('data/text.txt', 'r', encoding='UTF-8')\n",
    "    for k, line in enumerate(file):\n",
    "        if k<150_000:\n",
    "            continue\n",
    "        try:\n",
    "            idxs = list(encoder.transform([line.strip()]))[0]\n",
    "        except:\n",
    "            print(traceback.format_exc())\n",
    "            continue\n",
    "        len_idxs = len(idxs)\n",
    "        c_step = len_idxs//maxlen\n",
    "        if c_step>1:\n",
    "            c_step = random.randint(1, c_step-1)        \n",
    "        for i in range(c_step):\n",
    "            zero_idxs = np.random.choice(list(range(4, maxlen-2)), 3)\n",
    "            input_seq = np.array(idxs[i*maxlen:(i+1)*maxlen-1])\n",
    "            input_seq[zero_idxs] = 0\n",
    "            output_seq = idxs[i*maxlen:(i+1)*maxlen]\n",
    "            yield [0] + list(input_seq), maxlen, maxlen, output_seq\n",
    "\n",
    "\n",
    "def parser(input_seq, len_seq, max_len, output_seq):\n",
    "    return {'input_seq':input_seq, 'len_seq': len_seq, 'max_len': max_len}, output_seq\n",
    "\n",
    "def input_fn_train(params, is_training):\n",
    "    dataset = tf.data.Dataset.from_generator(lambda: gen_train(),\n",
    "                                             (tf.int64,tf.int64,tf.int64, tf.int64),\n",
    "                                              output_shapes=(tf.TensorShape([None]), \n",
    "                                                             tf.TensorShape([]),\n",
    "                                                             tf.TensorShape([]),\n",
    "                                                             tf.TensorShape([None])))\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "\n",
    "    dataset = dataset.batch(params['batch_size'])\n",
    "    dataset = dataset.map(parser)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "def build_model(features, params, is_training):\n",
    "    \n",
    "    # Embedding matrix\n",
    "    bpe_emb_matrix = tf.get_variable('bpe_embedding_matrix',\n",
    "                                 shape=[params['vocab_size'], params['emb_size']],\n",
    "                                 dtype=tf.float32)\n",
    "\n",
    "    def encode(x):\n",
    "        # embedding\n",
    "        embs = tf.nn.embedding_lookup(bpe_emb_matrix, x['input_seq'])\n",
    "        # dropout\n",
    "        dropout_emb = tf.layers.dropout(inputs=embs, \n",
    "                                        rate=0.1, \n",
    "                                        training=is_training)\n",
    "        # lstm\n",
    "        lstm_cell_1 = tf.nn.rnn_cell.GRUCell(250)\n",
    "        outputs, final_states = tf.nn.dynamic_rnn(\n",
    "            lstm_cell_1, dropout_emb, sequence_length=x['len_seq'], dtype=tf.float32)\n",
    "\n",
    "        # for futher clf\n",
    "        max_pool = tf.reduce_max(input_tensor=outputs, axis=1)\n",
    "        mean_pool = tf.reduce_mean(input_tensor=outputs, axis=1)\n",
    "        concat_pools = tf.concat((mean_pool, max_pool, final_states),1)\n",
    "        \n",
    "        # for lm\n",
    "        dropout_lstm = tf.layers.dropout(inputs=outputs, \n",
    "                                        rate=0.1, \n",
    "                                        training=is_training)\n",
    "        logits = tf.layers.dense(dropout_lstm, params['vocab_size'])\n",
    "        \n",
    "        \n",
    "        return logits, concat_pools\n",
    "\n",
    "    \n",
    "    with tf.variable_scope('encoder'):\n",
    "        logits, concat_pools = encode(features)\n",
    "    \n",
    "    return logits, concat_pools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'ckpt/ulmfit_experiment_10', '_tf_random_seed': 123, '_save_summary_steps': 5, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001A1F1F86A58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-8-5fced8459b41>:15: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-8-5fced8459b41>:17: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-5fced8459b41>:19: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-5fced8459b41>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-d3484d4eae22>:8: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ckpt/ulmfit_experiment_10\\model.ckpt-5000\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:loss = 4.6004977, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 0.634347\n",
      "INFO:tensorflow:loss = 4.4459624, step = 5101 (157.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658554\n",
      "INFO:tensorflow:loss = 4.4493, step = 5201 (151.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.642279\n",
      "INFO:tensorflow:loss = 4.462459, step = 5301 (155.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.626285\n",
      "INFO:tensorflow:loss = 4.582265, step = 5401 (159.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.642065\n",
      "INFO:tensorflow:loss = 4.436539, step = 5501 (155.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656188\n",
      "INFO:tensorflow:loss = 4.213991, step = 5601 (152.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657138\n",
      "INFO:tensorflow:loss = 4.4052024, step = 5701 (152.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65688\n",
      "INFO:tensorflow:loss = 4.42253, step = 5801 (152.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657595\n",
      "INFO:tensorflow:loss = 4.119865, step = 5901 (152.069 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\mrdro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 0.646541\n",
      "INFO:tensorflow:loss = 3.9645085, step = 6001 (154.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659296\n",
      "INFO:tensorflow:loss = 4.380727, step = 6101 (151.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657643\n",
      "INFO:tensorflow:loss = 4.447725, step = 6201 (152.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660428\n",
      "INFO:tensorflow:loss = 4.2833323, step = 6301 (151.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659789\n",
      "INFO:tensorflow:loss = 4.5232754, step = 6401 (151.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658087\n",
      "INFO:tensorflow:loss = 4.1133175, step = 6501 (151.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658541\n",
      "INFO:tensorflow:loss = 4.1807246, step = 6601 (151.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658939\n",
      "INFO:tensorflow:loss = 4.2997866, step = 6701 (151.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659169\n",
      "INFO:tensorflow:loss = 4.1432223, step = 6801 (151.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659685\n",
      "INFO:tensorflow:loss = 4.1676483, step = 6901 (151.587 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648587\n",
      "INFO:tensorflow:loss = 4.1584735, step = 7001 (154.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660445\n",
      "INFO:tensorflow:loss = 4.2406006, step = 7101 (151.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660715\n",
      "INFO:tensorflow:loss = 3.9595184, step = 7201 (151.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659095\n",
      "INFO:tensorflow:loss = 4.1392903, step = 7301 (151.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658094\n",
      "INFO:tensorflow:loss = 4.1158376, step = 7401 (151.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659798\n",
      "INFO:tensorflow:loss = 4.3689227, step = 7501 (151.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.316588, step = 7601 (151.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659958\n",
      "INFO:tensorflow:loss = 4.162794, step = 7701 (151.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660054\n",
      "INFO:tensorflow:loss = 4.048342, step = 7801 (151.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65877\n",
      "INFO:tensorflow:loss = 4.1756907, step = 7901 (151.798 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648661\n",
      "INFO:tensorflow:loss = 4.0562077, step = 8001 (154.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659199\n",
      "INFO:tensorflow:loss = 4.0962, step = 8101 (151.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659212\n",
      "INFO:tensorflow:loss = 4.1359425, step = 8201 (151.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65807\n",
      "INFO:tensorflow:loss = 4.30689, step = 8301 (151.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659706\n",
      "INFO:tensorflow:loss = 4.0469546, step = 8401 (151.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657238\n",
      "INFO:tensorflow:loss = 4.170924, step = 8501 (152.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659585\n",
      "INFO:tensorflow:loss = 4.1271634, step = 8601 (151.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659104\n",
      "INFO:tensorflow:loss = 4.1537843, step = 8701 (151.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659273\n",
      "INFO:tensorflow:loss = 4.132695, step = 8801 (151.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659416\n",
      "INFO:tensorflow:loss = 4.02168, step = 8901 (151.649 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.647775\n",
      "INFO:tensorflow:loss = 3.8653924, step = 9001 (154.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658541\n",
      "INFO:tensorflow:loss = 4.127778, step = 9101 (151.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659208\n",
      "INFO:tensorflow:loss = 4.0019794, step = 9201 (151.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658278\n",
      "INFO:tensorflow:loss = 3.8315434, step = 9301 (151.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65947\n",
      "INFO:tensorflow:loss = 4.2076464, step = 9401 (151.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660637\n",
      "INFO:tensorflow:loss = 4.060236, step = 9501 (151.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659437\n",
      "INFO:tensorflow:loss = 3.919339, step = 9601 (151.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65955\n",
      "INFO:tensorflow:loss = 3.9714427, step = 9701 (151.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657164\n",
      "INFO:tensorflow:loss = 3.9451425, step = 9801 (152.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658874\n",
      "INFO:tensorflow:loss = 3.9458387, step = 9901 (151.774 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.649044\n",
      "INFO:tensorflow:loss = 3.9192784, step = 10001 (154.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65942\n",
      "INFO:tensorflow:loss = 3.9433587, step = 10101 (151.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66018\n",
      "INFO:tensorflow:loss = 4.1134377, step = 10201 (151.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658692\n",
      "INFO:tensorflow:loss = 4.0132704, step = 10301 (151.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660126\n",
      "INFO:tensorflow:loss = 4.0170865, step = 10401 (151.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659186\n",
      "INFO:tensorflow:loss = 4.119704, step = 10501 (151.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660241\n",
      "INFO:tensorflow:loss = 3.8448007, step = 10601 (151.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658156\n",
      "INFO:tensorflow:loss = 3.9127367, step = 10701 (151.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658602\n",
      "INFO:tensorflow:loss = 3.8037755, step = 10801 (151.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659937\n",
      "INFO:tensorflow:loss = 4.1004, step = 10901 (151.529 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.647288\n",
      "INFO:tensorflow:loss = 4.050433, step = 11001 (154.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65845\n",
      "INFO:tensorflow:loss = 3.856244, step = 11101 (151.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659229\n",
      "INFO:tensorflow:loss = 3.894301, step = 11201 (151.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657886\n",
      "INFO:tensorflow:loss = 3.6502752, step = 11301 (152.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659598\n",
      "INFO:tensorflow:loss = 4.1295443, step = 11401 (151.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659386\n",
      "INFO:tensorflow:loss = 3.7166667, step = 11501 (151.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660293\n",
      "INFO:tensorflow:loss = 3.8357904, step = 11601 (151.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658831\n",
      "INFO:tensorflow:loss = 3.9857917, step = 11701 (151.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658342\n",
      "INFO:tensorflow:loss = 3.9142497, step = 11801 (151.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659454\n",
      "INFO:tensorflow:loss = 4.1996946, step = 11901 (151.640 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648252\n",
      "INFO:tensorflow:loss = 3.8482616, step = 12001 (154.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66045\n",
      "INFO:tensorflow:loss = 4.172625, step = 12101 (151.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658915\n",
      "INFO:tensorflow:loss = 4.0143695, step = 12201 (151.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659607\n",
      "INFO:tensorflow:loss = 3.628194, step = 12301 (151.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659614\n",
      "INFO:tensorflow:loss = 4.046732, step = 12401 (151.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66005\n",
      "INFO:tensorflow:loss = 3.8949356, step = 12501 (151.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660502\n",
      "INFO:tensorflow:loss = 3.7907221, step = 12601 (151.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659429\n",
      "INFO:tensorflow:loss = 3.791037, step = 12701 (151.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657763\n",
      "INFO:tensorflow:loss = 3.8665512, step = 12801 (152.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658974\n",
      "INFO:tensorflow:loss = 4.085915, step = 12901 (151.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648958\n",
      "INFO:tensorflow:loss = 3.8830023, step = 13001 (154.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659394\n",
      "INFO:tensorflow:loss = 3.886706, step = 13101 (151.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659563\n",
      "INFO:tensorflow:loss = 3.805063, step = 13201 (151.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659377\n",
      "INFO:tensorflow:loss = 4.1528206, step = 13301 (151.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659459\n",
      "INFO:tensorflow:loss = 3.931226, step = 13401 (151.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659307\n",
      "INFO:tensorflow:loss = 3.9805083, step = 13501 (151.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65965\n",
      "INFO:tensorflow:loss = 3.7911675, step = 13601 (151.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660197\n",
      "INFO:tensorflow:loss = 3.88832, step = 13701 (151.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660432\n",
      "INFO:tensorflow:loss = 3.687018, step = 13801 (151.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658593\n",
      "INFO:tensorflow:loss = 3.935758, step = 13901 (151.839 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.646383\n",
      "INFO:tensorflow:loss = 4.0472865, step = 14001 (154.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660236\n",
      "INFO:tensorflow:loss = 3.8551586, step = 14101 (151.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65975\n",
      "INFO:tensorflow:loss = 3.8955712, step = 14201 (151.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659056\n",
      "INFO:tensorflow:loss = 4.0050626, step = 14301 (151.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660097\n",
      "INFO:tensorflow:loss = 4.015166, step = 14401 (151.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659424\n",
      "INFO:tensorflow:loss = 3.9990678, step = 14501 (151.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659615\n",
      "INFO:tensorflow:loss = 3.9968998, step = 14601 (151.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659759\n",
      "INFO:tensorflow:loss = 3.8971078, step = 14701 (151.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660628\n",
      "INFO:tensorflow:loss = 3.825995, step = 14801 (151.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65968\n",
      "INFO:tensorflow:loss = 3.7920403, step = 14901 (151.588 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.649614\n",
      "INFO:tensorflow:loss = 3.6701477, step = 15001 (153.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65919\n",
      "INFO:tensorflow:loss = 3.883093, step = 15101 (151.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659741\n",
      "INFO:tensorflow:loss = 3.671018, step = 15201 (151.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659962\n",
      "INFO:tensorflow:loss = 4.0345635, step = 15301 (151.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659186\n",
      "INFO:tensorflow:loss = 3.8590765, step = 15401 (151.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659963\n",
      "INFO:tensorflow:loss = 3.7815099, step = 15501 (151.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659854\n",
      "INFO:tensorflow:loss = 3.4925869, step = 15601 (151.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658909\n",
      "INFO:tensorflow:loss = 3.6029932, step = 15701 (151.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658939\n",
      "INFO:tensorflow:loss = 3.6428533, step = 15801 (151.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658156\n",
      "INFO:tensorflow:loss = 3.8112009, step = 15901 (151.940 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.646847\n",
      "INFO:tensorflow:loss = 3.8144557, step = 16001 (154.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660163\n",
      "INFO:tensorflow:loss = 3.8989801, step = 16101 (151.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659693\n",
      "INFO:tensorflow:loss = 3.887374, step = 16201 (151.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660567\n",
      "INFO:tensorflow:loss = 4.009243, step = 16301 (151.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659216\n",
      "INFO:tensorflow:loss = 4.1809206, step = 16401 (151.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65955\n",
      "INFO:tensorflow:loss = 3.9522858, step = 16501 (151.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660128\n",
      "INFO:tensorflow:loss = 3.9441187, step = 16601 (151.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658762\n",
      "INFO:tensorflow:loss = 3.8176084, step = 16701 (151.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660263\n",
      "INFO:tensorflow:loss = 3.7530587, step = 16801 (151.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658589\n",
      "INFO:tensorflow:loss = 4.0616436, step = 16901 (151.840 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.64689\n",
      "INFO:tensorflow:loss = 3.8081355, step = 17001 (154.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650382\n",
      "INFO:tensorflow:loss = 3.953215, step = 17101 (153.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.654043\n",
      "INFO:tensorflow:loss = 3.817956, step = 17201 (152.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.653089\n",
      "INFO:tensorflow:loss = 3.728643, step = 17301 (153.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.650171\n",
      "INFO:tensorflow:loss = 3.7865684, step = 17401 (153.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659563\n",
      "INFO:tensorflow:loss = 3.6871364, step = 17501 (151.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658896\n",
      "INFO:tensorflow:loss = 3.749828, step = 17601 (151.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660024\n",
      "INFO:tensorflow:loss = 4.114185, step = 17701 (151.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659428\n",
      "INFO:tensorflow:loss = 3.6391864, step = 17801 (151.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66045\n",
      "INFO:tensorflow:loss = 4.1613803, step = 17901 (151.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.648215\n",
      "INFO:tensorflow:loss = 3.6161082, step = 18001 (154.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659906\n",
      "INFO:tensorflow:loss = 3.869931, step = 18101 (151.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659169\n",
      "INFO:tensorflow:loss = 3.8115811, step = 18201 (151.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659828\n",
      "INFO:tensorflow:loss = 4.0637217, step = 18301 (151.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659793\n",
      "INFO:tensorflow:loss = 3.7665014, step = 18401 (151.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659355\n",
      "INFO:tensorflow:loss = 3.9322622, step = 18501 (151.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659099\n",
      "INFO:tensorflow:loss = 3.8568466, step = 18601 (151.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659417\n",
      "INFO:tensorflow:loss = 3.6155858, step = 18701 (151.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658675\n",
      "INFO:tensorflow:loss = 3.5387094, step = 18801 (151.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657893\n",
      "INFO:tensorflow:loss = 3.8902633, step = 18901 (152.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.647478\n",
      "INFO:tensorflow:loss = 3.7684033, step = 19001 (154.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658511\n",
      "INFO:tensorflow:loss = 4.126544, step = 19101 (151.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658822\n",
      "INFO:tensorflow:loss = 3.7869859, step = 19201 (151.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.657821\n",
      "INFO:tensorflow:loss = 3.637629, step = 19301 (152.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.65965\n",
      "INFO:tensorflow:loss = 3.7589757, step = 19401 (151.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660423\n",
      "INFO:tensorflow:loss = 3.8009555, step = 19501 (151.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659281\n",
      "INFO:tensorflow:loss = 3.9549065, step = 19601 (151.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660537\n",
      "INFO:tensorflow:loss = 3.5421636, step = 19701 (151.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659516\n",
      "INFO:tensorflow:loss = 3.9355206, step = 19801 (151.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659667\n",
      "INFO:tensorflow:loss = 3.815741, step = 19901 (151.592 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.649295\n",
      "INFO:tensorflow:loss = 3.8566024, step = 20001 (154.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660097\n",
      "INFO:tensorflow:loss = 3.779541, step = 20101 (151.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659889\n",
      "INFO:tensorflow:loss = 3.6371882, step = 20201 (151.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.661277\n",
      "INFO:tensorflow:loss = 3.719201, step = 20301 (151.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658191\n",
      "INFO:tensorflow:loss = 3.9628484, step = 20401 (151.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66008\n",
      "INFO:tensorflow:loss = 3.8943548, step = 20501 (151.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659771\n",
      "INFO:tensorflow:loss = 3.894042, step = 20601 (151.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659572\n",
      "INFO:tensorflow:loss = 3.808614, step = 20701 (151.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.656295\n",
      "INFO:tensorflow:loss = 3.8746893, step = 20801 (152.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660032\n",
      "INFO:tensorflow:loss = 3.6836493, step = 20901 (151.509 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.649123\n",
      "INFO:tensorflow:loss = 3.7709515, step = 21001 (154.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659642\n",
      "INFO:tensorflow:loss = 3.7629383, step = 21101 (151.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660119\n",
      "INFO:tensorflow:loss = 3.6888962, step = 21201 (151.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659798\n",
      "INFO:tensorflow:loss = 3.78514, step = 21301 (151.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658666\n",
      "INFO:tensorflow:loss = 3.6309946, step = 21401 (151.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66015\n",
      "INFO:tensorflow:loss = 3.5190413, step = 21501 (151.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659615\n",
      "INFO:tensorflow:loss = 3.9689538, step = 21601 (151.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658446\n",
      "INFO:tensorflow:loss = 3.69052, step = 21701 (151.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660254\n",
      "INFO:tensorflow:loss = 3.8050928, step = 21801 (151.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.66058\n",
      "INFO:tensorflow:loss = 4.1233664, step = 21901 (151.382 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into ckpt/ulmfit_experiment_10\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.6488\n",
      "INFO:tensorflow:loss = 3.7162955, step = 22001 (154.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660802\n",
      "INFO:tensorflow:loss = 3.913487, step = 22101 (151.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658174\n",
      "INFO:tensorflow:loss = 3.6887374, step = 22201 (151.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660484\n",
      "INFO:tensorflow:loss = 3.6863408, step = 22301 (151.404 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.660524\n",
      "INFO:tensorflow:loss = 3.5700607, step = 22401 (151.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659793\n",
      "INFO:tensorflow:loss = 3.8627696, step = 22501 (151.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.658878\n",
      "INFO:tensorflow:loss = 3.829917, step = 22601 (151.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659446\n",
      "INFO:tensorflow:loss = 3.621438, step = 22701 (151.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.660245\n",
      "INFO:tensorflow:loss = 3.7067902, step = 22801 (151.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.659832\n",
      "INFO:tensorflow:loss = 3.7158945, step = 22901 (151.553 sec)\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    with tf.variable_scope('model'):\n",
    "        logits, concat_pools = build_model(features, params, is_training)\n",
    "    \n",
    "    weight_mask = tf.to_float(tf.sequence_mask(features['max_len']))\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, labels, weight_mask)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    global_step = tf.train.get_global_step()\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model_params = {\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'emb_size': 100,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 1\n",
    "}\n",
    "model_dir = 'ckpt/ulmfit_experiment_10'\n",
    "config = tf.estimator.RunConfig(tf_random_seed=123,\n",
    "                                model_dir=model_dir,\n",
    "                                save_summary_steps=5,\n",
    "                               save_checkpoints_steps=1000)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn,\n",
    "                                   params=model_params,\n",
    "                                   config=config)\n",
    "estimator.train(input_fn=lambda: input_fn_train(model_params, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
